{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c587a72",
   "metadata": {},
   "source": [
    "Importing the modules and suppressing the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "80f2bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e0a13",
   "metadata": {},
   "source": [
    "Loading the Dataset from keras library itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "321f2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb #type: ignore\n",
    "vocab_size=10000\n",
    "max_len=100\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084c26e",
   "metadata": {},
   "source": [
    "padding words these to make them of equal sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "49c7eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences #type: ignore\n",
    "x_train=pad_sequences(x_train,maxlen=max_len,padding='post')\n",
    "x_test=pad_sequences(x_test,maxlen=max_len,padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45dbfe2",
   "metadata": {},
   "source": [
    "Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "04335c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential  #type: ignore\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense #type: ignore\n",
    "model=Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128,input_length=max_len),\n",
    "    LSTM(32,dropout=0.5, recurrent_dropout=0.5),\n",
    "    Dense(16,activation='relu'),\n",
    "    Dropout(0.6),\n",
    "    Dense(1,activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eca944",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3162721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b2056",
   "metadata": {},
   "source": [
    "Training the model and loading the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5529c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.5913 - loss: 0.6569 - val_accuracy: 0.7685 - val_loss: 0.4845\n",
      "Epoch 2/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.7746 - loss: 0.4864 - val_accuracy: 0.7706 - val_loss: 0.4600\n",
      "Epoch 3/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - accuracy: 0.8209 - loss: 0.4310 - val_accuracy: 0.8111 - val_loss: 0.4214\n",
      "Epoch 4/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.8530 - loss: 0.3741 - val_accuracy: 0.8264 - val_loss: 0.4022\n",
      "Epoch 5/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 73ms/step - accuracy: 0.8687 - loss: 0.3384 - val_accuracy: 0.8252 - val_loss: 0.4087\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from keras.models import load_model\n",
    "if (os.path.exists('sentiment_analysis_model.keras')):\n",
    "    model=load_model('sentiment_analysis_model.keras')\n",
    "else:\n",
    "    history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
    "    with open('training_history.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "with open('training_history.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc63614",
   "metadata": {},
   "source": [
    "Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6468c175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.8265 - loss: 0.4139\n",
      "Test Loss: 0.40866273641586304\n",
      "Test Accuracy: 82.52%\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss}\\nTest Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102c09f",
   "metadata": {},
   "source": [
    "since the first 3 indexes are already reserved in keras dataset. We are updating the index to +3 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "index_word = {v + 3: k for k, v in word_index.items()} \n",
    "word_index = {k: (v + 3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c882b",
   "metadata": {},
   "source": [
    "Function to preprocessing the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf1568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rangra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "\n",
    "def correct_spelling(text):\n",
    "    return str(TextBlob(text).correct())\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def preprocess_review(review,max_len=max_len):\n",
    "    tokens=review.lower()\n",
    "    text=tokens.translate(str.maketrans('','',string.punctuation))\n",
    "    text=' '.join([word for word in text.split() if word not in stop_words])\n",
    "    text=[word for word in text.split() if word.isalpha()]\n",
    "    text = [correct_spelling(word) for word in text]\n",
    "    sequence = [min(word_index.get(word, 2), vocab_size - 1) for word in text]\n",
    "    padded=pad_sequences([sequence],maxlen=max_len,padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b3b69",
   "metadata": {},
   "source": [
    "Input review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3e241150",
   "metadata": {},
   "outputs": [],
   "source": [
    "review=input(\"Enter your review: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e806e35",
   "metadata": {},
   "source": [
    "preprocessed the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "be666623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['now', 'cinematic', 'masterpiece', 'especially', 'loved', 'plot', 'went', 'absolutely', 'nowhere', 'two', 'hours', 'true', 'innovation', 'way', 'characters', 'made', 'worst', 'possible', 'decisions', 'every', 'five', 'minutes', 'genius', 'rare', 'see', 'film', 'boldly', 'commit', 'completely', 'forgettable', 'oscarworthy', 'truly']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "padded_review=preprocess_review(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb53ab",
   "metadata": {},
   "source": [
    "Predicted the model. It gives a probability as we have used sigmoid as activation function in output layer. The output is a 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3f25026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction=model.predict(padded_review)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72933c",
   "metadata": {},
   "source": [
    "Printing the sentiment of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "23c6a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wow, what a cinematic masterpiece! I especially loved how the plot went absolutely nowhere for two hours — true innovation! And the way the characters made the worst possible decisions every five minutes? Genius. It's rare to see a film so boldly commit to being completely forgettable. Oscar-worthy, truly.\n",
      "Sentiment : Negative (92.85%)\n"
     ]
    }
   ],
   "source": [
    "if prediction >= 0.5:\n",
    "    print(f\"\\n{review}\\nSentiment : Positive ({prediction*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"\\n{review}\\nSentiment : Negative ({100- prediction*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a1628",
   "metadata": {},
   "source": [
    "This is all there is to it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989b4f8a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
